{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0776052-ace9-408c-a5a0-8767e013a46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/julianramirez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julianramirez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import praw\n",
    "from pytrends.request import TrendReq\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import interpolate\n",
    "import feedparser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8fddea-d4ba-4c71-828b-7852920eb2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/julianramirez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7d47b9-6b2b-4393-b243-638e36e5297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 2022-11-12\n",
      "End Date: 2024-11-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "end_date = datetime.today()\n",
    "\n",
    "start_date = end_date - timedelta(days=720)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"Start Date:\", start_date_str)\n",
    "print(\"End Date:\", end_date_str)\n",
    "\n",
    "ipc = yf.download('^MXX', start=start_date_str, end=end_date_str, interval='1d')\n",
    "ipc.reset_index(inplace=True)\n",
    "ipc['Date'] = pd.to_datetime(ipc['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a714f74-d11d-4b75-be11-6afad1b2ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 87 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and titles have been saved to 'news_titles.csv'.\n"
     ]
    }
   ],
   "source": [
    "def get_google_news_rss_feed(feed_url):\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    if feed.bozo:\n",
    "        print(\"Error parsing feed:\", feed.bozo_exception)\n",
    "        return []\n",
    "    if not feed.entries:\n",
    "        print(\"No entries found in the feed.\")\n",
    "        return []\n",
    "    articles = []\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title if 'title' in entry else 'No title'\n",
    "        summary = entry.summary if 'summary' in entry else 'No summary'\n",
    "        published = datetime(*entry.published_parsed[:6]) if 'published_parsed' in entry else None\n",
    "        articles.append({\n",
    "            'title': title,\n",
    "            'content': summary,\n",
    "            'date': published\n",
    "        })\n",
    "    return articles\n",
    "\n",
    "# Collect news articles\n",
    "bolsa_rss_url = \"https://news.google.com/rss/search?q=Bolsa+Mexicana+de+Valores&hl=es-419&gl=MX&ceid=MX:es-419\"\n",
    "news_articles = get_google_news_rss_feed(bolsa_rss_url)\n",
    "if news_articles:\n",
    "    print(f\"Collected {len(news_articles)} articles.\")\n",
    "else:\n",
    "    print(\"No articles were collected.\")\n",
    "\n",
    "def preprocess_text(text, stop_words):\n",
    "    if not isinstance(text, str):\n",
    "        text = ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^a-záéíóúñ\\s]', '', text)\n",
    "    tokens = word_tokenize(text, language='spanish')\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#sentiment analysis model\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    try:\n",
    "        result = sentiment_pipeline(text[:512])[0]  # Truncate text to 512 tokens\n",
    "        label = result['label']\n",
    "        score = int(label.split()[0])  # Extract the number from '1 star', '2 stars', etc.\n",
    "        normalized_score = (score - 3) / 2  # Normalize to range [-1, 1]\n",
    "        return normalized_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "news_df = pd.DataFrame(news_articles)\n",
    "if 'date' in news_df.columns:\n",
    "    news_df['Date'] = pd.to_datetime(news_df['date']).dt.normalize()\n",
    "    news_df.drop('date', axis=1, inplace=True)\n",
    "else:\n",
    "    news_df['Date'] = pd.to_datetime(news_df['published']).dt.normalize()\n",
    "news_df['combined_text'] = news_df['title'].astype(str) + ' ' + news_df['content'].astype(str)\n",
    "news_df['content_clean'] = news_df['combined_text'].apply(lambda x: preprocess_text(x, stop_words))\n",
    "news_df['sentiment_score'] = news_df['content_clean'].apply(get_sentiment_score)\n",
    "\n",
    "desired_columns = ['Date', 'title']\n",
    "\n",
    "news_df[desired_columns].to_csv('news_titles.csv', index=False)\n",
    "\n",
    "print(\"Date and titles have been saved to 'news_titles.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0be9734d-e50e-4c1d-ad94-8c7d31c05d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released 7 days ago.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in subreddit: MexicoBursatil\n",
      "Searching in subreddit: MexicoFinanciero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reddit API \n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"fbtWruG8aopQ5chxNLpURw\",\n",
    "    client_secret=\"hGgoXi6sA0Qv0wgAezpdXqGvOgc_1Q\",\n",
    "    user_agent=\"marketsentimentbmv\"\n",
    ")\n",
    "\n",
    "reddit.read_only = True\n",
    "\n",
    "def get_reddit_posts(subreddits, query, limit=10):\n",
    "    posts = []\n",
    "    for subreddit in subreddits:\n",
    "        print(f\"Searching in subreddit: {subreddit}\")\n",
    "        subreddit_obj = reddit.subreddit(subreddit)\n",
    "        for submission in subreddit_obj.search(query, limit=limit):\n",
    "            posts.append({\n",
    "                'title': submission.title,\n",
    "                'content': submission.selftext,\n",
    "                'created': pd.to_datetime(submission.created_utc, unit='s')\n",
    "            })\n",
    "    return posts\n",
    "\n",
    "subreddits = ['MexicoBursatil', 'MexicoFinanciero']\n",
    "query = 'Acciones' , 'comprar', 'vender'\n",
    "reddit_posts = get_reddit_posts(subreddits, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f116240-1329-4e91-ad69-adba0b9b6d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                title  \\\n",
      "0   10 Acciones Que Warren Buffett Acaba De Compra...   \n",
      "1   De los errores se aprende y cuando se aprende ...   \n",
      "2   Creen que bitcoin baje mas? Es buen momento pa...   \n",
      "3                                   Venta de acciones   \n",
      "4   Vale la pena meterle al fondo de Gbm? (GBMMINT...   \n",
      "5                    Me gané unas acciones, y ahora?    \n",
      "6                                 Etfs de acumulación   \n",
      "7                                   Inversión en QQQM   \n",
      "8   ¿Cuál es el funcionamiento de la inversión en ...   \n",
      "9   ¿Qué son los “Fully Paid Lending programs” y e...   \n",
      "10  Madres... si hubiera comprado gansitos en 2018...   \n",
      "11  Que tan rentable es vender carros al sur de Me...   \n",
      "12               Vender bitcoin para meterlo a cetes?   \n",
      "13  Como lidiar con la frustacion de vender accion...   \n",
      "14  ¿Puedo vender mi casa a un familiar y comprarl...   \n",
      "15               Acciones en GBM no se pueden vender.   \n",
      "16  El mejor momento para vender tu carro y compra...   \n",
      "17          ¿Cómo reportar ingresos por vender nudes?   \n",
      "18  Cuando es mejor vender una propiedad vieja (40...   \n",
      "19                    ¿Dónde empeñar o vender mi Oro?   \n",
      "\n",
      "                                              content       Date  \\\n",
      "0   ¿Qué acciones ha comprado y vendido Warren Buf... 2022-06-03   \n",
      "1   La gente comenta o el comentario de siempre es... 2024-10-01   \n",
      "2                                                     2024-10-03   \n",
      "3   Hola, tengo 577 acciones de WALMEX en GBM, per... 2024-10-16   \n",
      "4   Cuando súper mamó la bolsa hace unas semanas p... 2024-08-15   \n",
      "5   Pues eso, en parte por mérito me gané unas acc... 2024-04-08   \n",
      "6   Alguno de ustedes invierte usando etf's de acu... 2024-02-11   \n",
      "7   Hola a todos. He estado intentando comprar una... 2024-01-31   \n",
      "8   ¿Qué consejos darían para principiante? Por fa... 2024-03-25   \n",
      "9   Hola, comunidad de r/MexicoBursatil\\n\\nHe esta... 2024-06-11   \n",
      "10                                                    2024-06-27   \n",
      "11  Hola, tengo 34(H) años recién me liquidaron de... 2024-05-04   \n",
      "12  Me gustaría saber su opinión sobre vender un p... 2023-06-17   \n",
      "13  Si me pudieran compartir experiencias personal... 2024-02-02   \n",
      "14  Supongamos que tengo un crédito hipotecario qu... 2024-10-30   \n",
      "15  Hace unos 2 años compre unas accione en GBM, y... 2024-10-05   \n",
      "16  Mi situación es la siguiente; Tengo un Nissan ... 2023-08-21   \n",
      "17  ¿Cómo se reporta ante el SAT si alguien vende ... 2023-06-10   \n",
      "18  Supongamos una casa en CDMX, con avaluo actual... 2024-03-31   \n",
      "19  Tengo un reloj Omega Constellation (1962) 18K ... 2024-02-17   \n",
      "\n",
      "                                        content_clean  sentiment_score  \n",
      "0   acciones warren buffett acaba comprar vender a...             -1.0  \n",
      "1   errores aprende aprende ejecuta gente comenta ...             -1.0  \n",
      "2         creen bitcoin baje mas buen momento comprar              1.0  \n",
      "3   venta acciones hola acciones walmex gbm quiero...             -1.0  \n",
      "4   vale pena meterle fondo gbm gbmmint bo súper m...             -0.5  \n",
      "5   gané unas acciones ahora pues parte mérito gan...             -1.0  \n",
      "6   etfs acumulación alguno ustedes invierte usand...             -1.0  \n",
      "7   inversión qqqm hola intentando comprar acción ...             -1.0  \n",
      "8   cuál funcionamiento inversión oro consejos dar...              1.0  \n",
      "9   fully paid lending programs existen méxico hol...             -1.0  \n",
      "10  madres si comprado gansitos ahorita podría ven...             -1.0  \n",
      "11  tan rentable vender carros sur mexico hola h a...              1.0  \n",
      "12  vender bitcoin meterlo cetes gustaría saber op...             -1.0  \n",
      "13  lidiar frustacion vender acciones despues subi...             -1.0  \n",
      "14  puedo vender casa familiar comprarla vuelta ti...             -1.0  \n",
      "15  acciones gbm pueden vender hace años compre un...             -1.0  \n",
      "16  mejor momento vender carro comprar mazda preci...             -1.0  \n",
      "17  cómo reportar ingresos vender nudes cómo repor...             -1.0  \n",
      "18  mejor vender propiedad vieja años lugar seguir...             -1.0  \n",
      "19  dónde empeñar vender oro reloj omega constella...             -1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reddit posts to DataFrame\n",
    "reddit_df = pd.DataFrame(reddit_posts)\n",
    "\n",
    "reddit_df['Date'] = reddit_df['created'].dt.normalize()\n",
    "reddit_df.drop('created', axis=1, inplace=True)\n",
    "\n",
    "# compute sentiment\n",
    "reddit_df['content_clean'] = reddit_df.apply(lambda x: preprocess_text(x['title'] + ' ' + x['content'], stop_words), axis=1)\n",
    "reddit_df['sentiment_score'] = reddit_df['content_clean'].apply(get_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af24f57a-2e44-430d-9a62-f99ee3634832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "def get_google_trends_data(keywords, timeframe='today 1-m'):\n",
    "    pytrends = TrendReq(hl='es-MX', tz=360)\n",
    "    pytrends.build_payload(keywords, cat=0, timeframe=timeframe, geo='MX', gprop='')\n",
    "    data = pytrends.interest_over_time()\n",
    "    return data\n",
    "\n",
    "\n",
    "keywords = ['BMV', 'inversiones', 'Acciones', 'comprar acciones']\n",
    "trends_data = get_google_trends_data(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b24ec63-89db-4b8a-a3e6-3df99ac5fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "        date  BMV  inversiones  Acciones  comprar acciones  isPartial\n",
      "0 2024-09-30    2            8        63                 0      False\n",
      "1 2024-10-01    3            6        54                 1      False\n",
      "2 2024-10-02    4            8        87                 1      False\n",
      "3 2024-10-03    4            9        92                 0      False\n",
      "4 2024-10-04    3           10        78                 1      False\n",
      "\n",
      "Datos con cambios porcentuales y aumentos significativos:\n",
      "        date  BMV  inversiones  Acciones  comprar acciones  isPartial  \\\n",
      "0 2024-09-30    2            8        63                 0      False   \n",
      "1 2024-10-01    3            6        54                 1      False   \n",
      "2 2024-10-02    4            8        87                 1      False   \n",
      "3 2024-10-03    4            9        92                 0      False   \n",
      "4 2024-10-04    3           10        78                 1      False   \n",
      "\n",
      "   BMV_pct_change  inversiones_pct_change  Acciones_pct_change  \\\n",
      "0             NaN                     NaN                  NaN   \n",
      "1       50.000000              -25.000000           -14.285714   \n",
      "2       33.333333               33.333333            61.111111   \n",
      "3        0.000000               12.500000             5.747126   \n",
      "4      -25.000000               11.111111           -15.217391   \n",
      "\n",
      "   comprar acciones_pct_change  BMV_sig_increase  inversiones_sig_increase  \\\n",
      "0                          NaN                 0                         0   \n",
      "1                          inf                 0                         0   \n",
      "2                          0.0                 0                         0   \n",
      "3                       -100.0                 0                         0   \n",
      "4                          inf                 0                         0   \n",
      "\n",
      "   Acciones_sig_increase  comprar acciones_sig_increase  \\\n",
      "0                      0                              0   \n",
      "1                      0                              1   \n",
      "2                      1                              0   \n",
      "3                      0                              0   \n",
      "4                      0                              1   \n",
      "\n",
      "   Google_Trends_Significant_Increase  \n",
      "0                                   0  \n",
      "1                                   1  \n",
      "2                                   1  \n",
      "3                                   0  \n",
      "4                                   1  \n"
     ]
    }
   ],
   "source": [
    "# Verificar si se obtuvieron datos\n",
    "if trends_data.empty:\n",
    "    print(\"No se obtuvieron datos de Google Trends. Verifica las palabras clave y el timeframe.\")\n",
    "else:\n",
    "    \n",
    "    trends_data.reset_index(inplace=True)\n",
    "    \n",
    "    print(\"Datos originales:\")\n",
    "    print(trends_data.head())\n",
    "    \n",
    "    # Calcular el cambio porcentual para cada palabra clave\n",
    "    for keyword in keywords:\n",
    "        trends_data[f'{keyword}_pct_change'] = trends_data[keyword].pct_change() * 100\n",
    "    \n",
    "    # Definir cambios significativos\n",
    "    significant_threshold = 51 \n",
    "    \n",
    "    # Crear columnas que indiquen si hubo un aumento significativo\n",
    "    for keyword in keywords:\n",
    "        trends_data[f'{keyword}_sig_increase'] = trends_data[f'{keyword}_pct_change'].apply(\n",
    "            lambda x: 1 if x > significant_threshold else 0\n",
    "        )\n",
    "    # Crear una columna que sume los aumentos significativos de todas las palabras clave\n",
    "    trend_sig_columns = [f'{keyword}_sig_increase' for keyword in keywords]\n",
    "    trends_data['Google_Trends_Significant_Increase'] = trends_data[trend_sig_columns].sum(axis=1)\n",
    "    \n",
    "    trends_data['date'] = pd.to_datetime(trends_data['date']).dt.normalize()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "303783a2-6914-449d-afcb-083490a62116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  BMV  inversiones  Acciones  comprar acciones  isPartial  \\\n",
      "0 2024-09-30    2            8        63                 0      False   \n",
      "1 2024-10-01    3            6        54                 1      False   \n",
      "2 2024-10-02    4            8        87                 1      False   \n",
      "3 2024-10-03    4            9        92                 0      False   \n",
      "4 2024-10-04    3           10        78                 1      False   \n",
      "\n",
      "   BMV_pct_change  inversiones_pct_change  Acciones_pct_change  \\\n",
      "0             NaN                     NaN                  NaN   \n",
      "1       50.000000              -25.000000           -14.285714   \n",
      "2       33.333333               33.333333            61.111111   \n",
      "3        0.000000               12.500000             5.747126   \n",
      "4      -25.000000               11.111111           -15.217391   \n",
      "\n",
      "   comprar acciones_pct_change  BMV_sig_increase  inversiones_sig_increase  \\\n",
      "0                          NaN                 0                         0   \n",
      "1                          inf                 0                         0   \n",
      "2                          0.0                 0                         0   \n",
      "3                       -100.0                 0                         0   \n",
      "4                          inf                 0                         0   \n",
      "\n",
      "   Acciones_sig_increase  comprar acciones_sig_increase  \\\n",
      "0                      0                              0   \n",
      "1                      0                              1   \n",
      "2                      1                              0   \n",
      "3                      0                              0   \n",
      "4                      0                              1   \n",
      "\n",
      "   Google_Trends_Significant_Increase  \n",
      "0                                   0  \n",
      "1                                   1  \n",
      "2                                   1  \n",
      "3                                   0  \n",
      "4                                   1  \n"
     ]
    }
   ],
   "source": [
    "trends_data['date'] = pd.to_datetime(trends_data['date']).dt.normalize()\n",
    "trends_data.rename(columns={'date': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f453104-c2e4-42b5-885d-b06d18fbd266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Google_Trends_Significant_Increase\n",
      "0  2024-09-30                                   0\n",
      "1  2024-10-01                                   1\n",
      "2  2024-10-02                                   1\n",
      "3  2024-10-03                                   0\n",
      "4  2024-10-04                                   1\n",
      "5  2024-10-05                                   0\n",
      "6  2024-10-06                                   0\n",
      "7  2024-10-07                                   3\n",
      "8  2024-10-08                                   0\n",
      "9  2024-10-09                                   1\n",
      "10 2024-10-10                                   0\n",
      "11 2024-10-11                                   0\n",
      "12 2024-10-12                                   0\n",
      "13 2024-10-13                                   2\n",
      "14 2024-10-14                                   1\n",
      "15 2024-10-15                                   1\n",
      "16 2024-10-16                                   0\n",
      "17 2024-10-17                                   1\n",
      "18 2024-10-18                                   0\n",
      "19 2024-10-19                                   0\n",
      "20 2024-10-20                                   0\n",
      "21 2024-10-21                                   2\n",
      "22 2024-10-22                                   0\n",
      "23 2024-10-23                                   0\n",
      "24 2024-10-24                                   0\n",
      "25 2024-10-25                                   0\n",
      "26 2024-10-26                                   0\n",
      "27 2024-10-27                                   0\n",
      "28 2024-10-28                                   3\n",
      "29 2024-10-29                                   0\n",
      "30 2024-10-30                                   0\n",
      "31 2024-10-31                                   1\n"
     ]
    }
   ],
   "source": [
    "trends_daily = trends_data[['Date', 'Google_Trends_Significant_Increase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85d504bb-e5f8-4687-a236-bb1a49f17765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  sentiment_score\n",
      "0  2024-08-30        -1.000000\n",
      "1  2024-09-10        -1.000000\n",
      "2  2024-09-20        -1.000000\n",
      "3  2024-10-09        -1.000000\n",
      "4  2024-10-11        -1.000000\n",
      "5  2024-10-16         0.000000\n",
      "6  2024-10-18         0.000000\n",
      "7  2024-10-19        -1.000000\n",
      "8  2024-10-21        -0.333333\n",
      "9  2024-10-22        -1.000000\n",
      "10 2024-10-23        -0.800000\n",
      "11 2024-10-24        -0.777778\n",
      "12 2024-10-25        -0.600000\n",
      "13 2024-10-26        -1.000000\n",
      "14 2024-10-27        -1.000000\n",
      "15 2024-10-28        -1.000000\n",
      "16 2024-10-29        -0.636364\n",
      "17 2024-10-30        -0.800000\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Aggregate News Sentiment by Date\n",
    "news_daily_sentiment = news_df.groupby('Date')['sentiment_score'].mean().reset_index()\n",
    "print(news_daily_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2d457ec-b5ca-4808-a070-98a008b4e5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  sentiment_score\n",
      "0  2022-06-03             -1.0\n",
      "1  2023-06-10             -1.0\n",
      "2  2023-06-17             -1.0\n",
      "3  2023-08-21             -1.0\n",
      "4  2024-01-31             -1.0\n",
      "5  2024-02-02             -1.0\n",
      "6  2024-02-11             -1.0\n",
      "7  2024-02-17             -1.0\n",
      "8  2024-03-25              1.0\n",
      "9  2024-03-31             -1.0\n",
      "10 2024-04-08             -1.0\n",
      "11 2024-05-04              1.0\n",
      "12 2024-06-11             -1.0\n",
      "13 2024-06-27             -1.0\n",
      "14 2024-08-15             -0.5\n",
      "15 2024-10-01             -1.0\n",
      "16 2024-10-03              1.0\n",
      "17 2024-10-05             -1.0\n",
      "18 2024-10-16             -1.0\n",
      "19 2024-10-30             -1.0\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Aggregate Reddit Sentiment by Date\n",
    "reddit_daily_sentiment = reddit_df.groupby('Date')['sentiment_score'].mean().reset_index()\n",
    "print(reddit_daily_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26983200-3038-4e86-8449-72e42a8ed3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1           NaN\n",
      "2      0.021525\n",
      "3      0.000850\n",
      "4      0.000356\n",
      "         ...   \n",
      "490    0.004121\n",
      "491    0.002320\n",
      "492    0.006430\n",
      "493    0.000834\n",
      "494    0.013162\n",
      "Name: Volatility, Length: 495, dtype: float64\n",
      "ipc shape: (495, 9)\n",
      "        Date  Volatility\n",
      "0 2022-11-10    0.010000\n",
      "1 2022-11-11    0.010000\n",
      "2 2022-11-14    0.021525\n",
      "3 2022-11-15    0.000850\n",
      "4 2022-11-16    0.000356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/2117013522.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ipc['Volatility'].fillna(default_volatility, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Volatility\n",
    "ipc = yf.download('^MXX', start=start_date_str, end=end_date_str, interval='1d')\n",
    "ipc.reset_index(inplace=True)\n",
    "ipc['Date'] = pd.to_datetime(ipc['Date'])\n",
    "ipc['Returns'] = ipc['Close'].pct_change()\n",
    "ipc['Volatility'] = ipc['Returns'].rolling(window=2).std() * np.sqrt(2)\n",
    "\n",
    "print(ipc['Volatility'])\n",
    "\n",
    "default_volatility = 0.01\n",
    "ipc['Volatility'].fillna(default_volatility, inplace=True)\n",
    "\n",
    "print(\"ipc shape:\", ipc.shape)\n",
    "print(ipc[['Date', 'Volatility']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afa7cfbb-8370-4a06-9a40-5e1fece3e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/2750046490.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sentiment_data.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Merge News and Reddit sentiment\n",
    "sentiment_data = pd.merge(\n",
    "    news_daily_sentiment,\n",
    "    reddit_daily_sentiment,\n",
    "    on='Date',\n",
    "    how='outer',\n",
    "    suffixes=('_news', '_reddit')\n",
    ")\n",
    "\n",
    "sentiment_data = pd.merge(\n",
    "    sentiment_data,\n",
    "    trends_daily,\n",
    "    on='Date',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "\n",
    "sentiment_data.fillna(method='ffill', inplace=True)\n",
    "sentiment_data.dropna(inplace=True)\n",
    "\n",
    "# Merge w md\n",
    "ipc_sentiment = pd.merge(sentiment_data, ipc[['Date', 'Volatility']], on='Date', how='left')\n",
    "ipc_sentiment.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "10f8faa7-916c-43a0-8321-dd0d6bc43556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in ipc DataFrame:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Returns', 'Volatility', 'Volume_30d_avg', 'Volume_90d_avg', 'Volume_vs_30d_avg', 'Volume_vs_90d_avg', 'Momentum', 'Momentum_30d_avg', 'Momentum_90d_avg', 'Momentum_vs_30d_avg', 'Momentum_vs_90d_avg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/512060625.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ipc['Volatility'].fillna(ipc['Volatility'].mean(), inplace=True)\n",
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/512060625.py:43: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ipc_sentiment.fillna(method='ffill', inplace=True)\n",
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/512060625.py:44: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ipc_sentiment.fillna(method='bfill', inplace=True)\n",
      "/var/folders/6q/jns7j9_90psfzrg2_z5bct3h0000gn/T/ipykernel_28322/512060625.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ipc_sentiment['Volatility_inv'].fillna(ipc_sentiment['Volatility_inv'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ipc['Returns'] = ipc['Close'].pct_change()\n",
    "\n",
    "\n",
    "ipc['Volatility'] = ipc['Returns'].rolling(window=30).std() * np.sqrt(30)\n",
    "ipc['Volatility'].fillna(ipc['Volatility'].mean(), inplace=True)\n",
    "\n",
    "ipc['Volume'] = ipc['Volume'].astype(float)\n",
    "\n",
    "ipc['Volume_30d_avg'] = ipc['Volume'].rolling(window=30).mean()\n",
    "ipc['Volume_vs_30d_avg'] = ipc['Volume'] / ipc['Volume_30d_avg']\n",
    "\n",
    "\n",
    "ipc['Momentum'] = ipc['Close'] - ipc['Close'].shift(1)\n",
    "ipc['Momentum_30d_avg'] = ipc['Momentum'].rolling(window=30).mean()\n",
    "ipc['Momentum_vs_30d_avg'] = ipc['Momentum'] / ipc['Momentum_30d_avg']\n",
    "\n",
    "\n",
    "print(\"Columns in ipc DataFrame:\")\n",
    "print(ipc.columns.tolist())\n",
    "\n",
    "# selecting ipc_metrics\n",
    "ipc_metrics = ipc[['Date', 'Volatility', 'Volume', 'Close', 'Momentum', 'Volume_30d_avg',\n",
    "                   'Volume_vs_30d_avg', 'Momentum_30d_avg',\n",
    "                   'Momentum_vs_30d_avg',]]\n",
    "\n",
    "# merging ipc_metrics with sentiment_data\n",
    "ipc_sentiment = pd.merge(\n",
    "    sentiment_data,\n",
    "    ipc_metrics,\n",
    "    on='Date',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "ipc_sentiment.sort_values('Date', inplace=True)\n",
    "ipc_sentiment.fillna(method='ffill', inplace=True)\n",
    "ipc_sentiment.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Invert Volatility\n",
    "ipc_sentiment['Volatility_inv'] = 1 / ipc_sentiment['Volatility']\n",
    "ipc_sentiment.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "ipc_sentiment['Volatility_inv'].fillna(ipc_sentiment['Volatility_inv'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9d0badfd-0790-4284-a613-5bed59b4ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  sentiment_score_news  sentiment_score_reddit  \\\n",
      "0   2022-11-10              0.000000                    0.25   \n",
      "1   2022-11-11              0.000000                    0.25   \n",
      "2   2022-11-14              0.000000                    0.25   \n",
      "3   2022-11-15              0.000000                    0.25   \n",
      "4   2022-11-16              0.000000                    0.25   \n",
      "..         ...                   ...                     ...   \n",
      "501 2024-10-27              0.000000                    0.00   \n",
      "502 2024-10-28              0.000000                    0.00   \n",
      "503 2024-10-29              0.363636                    0.00   \n",
      "504 2024-10-30              0.200000                    0.00   \n",
      "505 2024-10-31              0.200000                    0.00   \n",
      "\n",
      "     Google_Trends_Significant_Increase  Volatility    Volume         Close  \\\n",
      "0                              0.000000    0.298831  0.073963  51031.710938   \n",
      "1                              0.000000    0.298831  0.083060  51959.199219   \n",
      "2                              0.000000    0.298831  0.080156  51785.128906   \n",
      "3                              0.000000    0.298831  0.064840  51655.679688   \n",
      "4                              0.000000    0.298831  0.074674  51544.941406   \n",
      "..                                  ...         ...       ...           ...   \n",
      "501                            0.000000    0.316984  0.085970  51784.328125   \n",
      "502                            1.000000    0.272299  0.088145  51816.300781   \n",
      "503                            0.000000    0.300310  0.089870  51166.289062   \n",
      "504                            0.000000    0.300310  0.089870  51166.289062   \n",
      "505                            0.333333    0.300310  0.089870  51166.289062   \n",
      "\n",
      "     Momentum  Volume_30d_avg  Volume_vs_30d_avg  Momentum_30d_avg  \\\n",
      "0    0.820414    1.787125e+08           0.052929        -25.260677   \n",
      "1    0.820414    1.787125e+08           0.052929        -25.260677   \n",
      "2    0.610203    1.787125e+08           0.052929        -25.260677   \n",
      "3    0.618718    1.787125e+08           0.052929        -25.260677   \n",
      "4    0.622289    1.787125e+08           0.052929        -25.260677   \n",
      "..        ...             ...                ...               ...   \n",
      "501  0.641278    2.363586e+08           0.107500         19.618880   \n",
      "502  0.649522    2.355738e+08           0.110587         -6.114323   \n",
      "503  0.519379    2.378762e+08           0.111660        -28.352083   \n",
      "504  0.519379    2.378762e+08           0.111660        -28.352083   \n",
      "505  0.519379    2.378762e+08           0.111660        -28.352083   \n",
      "\n",
      "     Momentum_vs_30d_avg  Volatility_inv  \n",
      "0               0.590745        0.472551  \n",
      "1               0.590745        0.472551  \n",
      "2               0.590745        0.472551  \n",
      "3               0.590745        0.472551  \n",
      "4               0.590745        0.472551  \n",
      "..                   ...             ...  \n",
      "501             0.586419        0.451376  \n",
      "502             0.584822        0.505052  \n",
      "503             0.594478        0.470795  \n",
      "504             0.594478        0.470795  \n",
      "505             0.594478        0.470795  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "features_to_normalize = [\n",
    "    'sentiment_score_news',\n",
    "    'sentiment_score_reddit',\n",
    "    'Google_Trends_Significant_Increase',\n",
    "    'Volatility',\n",
    "    'Volume',\n",
    "    'Momentum',\n",
    "    'Volume_vs_30d_avg',\n",
    "    'Momentum_vs_30d_avg',\n",
    "    'Volatility_inv'\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaling\n",
    "ipc_sentiment_scaled = ipc_sentiment.copy()\n",
    "ipc_sentiment_scaled[features_to_normalize] = scaler.fit_transform(\n",
    "    ipc_sentiment[features_to_normalize]\n",
    ")\n",
    "\n",
    "print(ipc_sentiment_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "309531cd-6428-452d-a201-416223e43579",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'sentiment_score_news': 0.25,\n",
    "    'sentiment_score_reddit': 0.25,\n",
    "    'Google_Trends_Significant_Increase':0.1,\n",
    "#25% Volatility\n",
    "    'Volatility_inv': 0.25,\n",
    "#25% market/volume\n",
    "    'Volume_vs_30d_avg': 0.15,\n",
    "    'Momentum_vs_30d_avg': 0.1,\n",
    "}\n",
    "\n",
    "features = list(weights.keys())\n",
    "\n",
    "ipc_sentiment_scaled.set_index('Date', inplace=True)\n",
    "\n",
    "def adjust_weights(row, weights):\n",
    "    available_weights = {}\n",
    "    total_weight = 0\n",
    "\n",
    "    for feature, weight in weights.items():\n",
    "        if pd.notna(row[feature]):\n",
    "            available_weights[feature] = weight\n",
    "            total_weight += weight\n",
    "\n",
    "    # Normalize weights\n",
    "    for feature in available_weights:\n",
    "        available_weights[feature] /= total_weight\n",
    "\n",
    "    return available_weights\n",
    "\n",
    "def calculate_sentiment_index(row):\n",
    "    adj_weights = adjust_weights(row, weights)\n",
    "    sentiment_index = 0\n",
    "    for feature, weight in adj_weights.items():\n",
    "        sentiment_index += row[feature] * weight\n",
    "    return sentiment_index * 100  # Scale to 0-100\n",
    "\n",
    "ipc_sentiment_scaled['Sentiment_Index'] = ipc_sentiment_scaled.apply(calculate_sentiment_index, axis=1)\n",
    "\n",
    "ipc_sentiment_scaled.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "19eedfb2-5e54-45d6-8690-f62cc36dea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with only 'Date' and 'Sentiment_Index' to save csv\n",
    "sentiment_index_df = ipc_sentiment_scaled[['Date', 'Sentiment_Index']]\n",
    "\n",
    "sentiment_index_df.to_csv('sentiment_index.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
